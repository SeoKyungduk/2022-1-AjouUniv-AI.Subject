{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e68239d",
   "metadata": {},
   "source": [
    "# 14_딥러닝(2)\n",
    "## - MNIST (필기체숫자) 인식 -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7a7b01",
   "metadata": {},
   "source": [
    "MNIST - 개요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fd4c89",
   "metadata": {},
   "source": [
    "- => MNIST\n",
    "- MNIST (Modified National Institute of Standards and Technology)는 손으로 직접 쓴 숫자(필기체 숫자)들로 이루어진 데이터 셋 (Data Set) 이며,\n",
    "- 우리가 새로운 프로그래밍 언어를 배울 때 'Hello, World'를 출력하는 것처럼, MNIST는 딥러닝을 배울 때 반드시 거쳐야 하는 'Hello, World' 같은 존재임.\n",
    "- MNIST는 0부터 9까지의 숫자 이미지로 구성되며, 60000개의 트레이닝 데이터와 10000개 테스트 데이터로 이루어져 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd87c83",
   "metadata": {},
   "source": [
    "MNIST - 구조 (1)\n",
    "- => mnist_train.csv\n",
    "- mnist_train.csv 파일에는 학습에 이용될 수 있도록 정답(lable)이 있는 총 60000개의 데이터 존재함. 1개의 데이터는 785개의 숫자가 콤마(,)로 분리 되어 있는데, 정답을 나타내는 1개의 숫자와 실제 필기체 숫자 이미지를 나타내는 784개의 숫자로 구성되어 잇음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16c9ef",
   "metadata": {},
   "source": [
    "- => mnist_test.csv\n",
    "- mnist_test.csv 파일에는 총 10000개의 데이터가 있으며, 학습을 마친 후에 구현된 딥러닝 아키텍처가 얼마나 잘 작동하는지 테스트 하기 위해 사용됨. 테스트 데이터 또한 정답(lable)이 포함된 785 개의 숫자로 되어 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55048efe",
   "metadata": {},
   "source": [
    "MNIST - 구조 (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4715df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST 가져오기 (numpy.loadtxt 활용)\n",
    "# training data\n",
    "import numpy as np\n",
    "\n",
    "training_data = np.loadtxt('mnist_train.csv', delimiter = ',', dtype = np.float32)\n",
    "test_data = np.loadtxt('mnist_test.csv', delimiter = ',', dtype = np.float32)\n",
    "\n",
    "print(\"training_data.shape = \", training_data.shape, \"test_data.shape = \", test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0175cc7",
   "metadata": {},
   "source": [
    "MNIST - 구조 (3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acce370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_data 이미지 표현\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = training_data[0][1:].reshape(28, 28)\n",
    "\n",
    "plt.imshow(img, cmap = 'gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f28fae1",
   "metadata": {},
   "source": [
    "NeuralNetwork class - MNIST (필기체 숫자) 인식 클래스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66258e8",
   "metadata": {},
   "source": [
    "- external function  \n",
    "  \n",
    "- def sigmoid(x): # 0 또는 1을 출력하기 위한 sigmoid 함수  \n",
    "\n",
    "- def numerical_derivative(f, x): # 수치미분함수  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e36dbee",
   "metadata": {},
   "source": [
    "- NeuralNetwork class\n",
    "\n",
    "- class NeuralNetwork:\n",
    "    def __init__(self, gate_name, xdata, tdata) # 입력/정답 데이터/가중치/바이어스 초기화  \n",
    "    def feed_forward(self) # feed forward 이용하여 손실함수 값 계산  \n",
    "    def error_val(self) # 손실함수 값 계산(외부 출력을 위해 사용됨)  \n",
    "    def train(self) # 수치미분을 이용하여 손실함수 최소값 찾는 method  \n",
    "    def predict(self, xdata) # 미래 값 예측 method  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c05c36",
   "metadata": {},
   "source": [
    "- usage\n",
    "- 입력노드 784개, 은닉노드 100개, 출력노드 10개의 NeuralNetwork 객체 생성\n",
    "- nn = NeuralNetwork(784, 100, 10)\n",
    "\n",
    "- for step in range(30001): # 60000개의 training data 중 50 % 데이터로 학습 진행\n",
    "    index = np.random.randint(0, 59999) # 60000개의 데이터 가운데 random 하게 30000개 선택\n",
    "    nn.train(training_data[index]) # random 하게 선택된 training_data를 이용하여 학습 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13d2da2",
   "metadata": {},
   "source": [
    "구현코드 - MNIST (필기체 숫자 인식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6196bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] external function (sigmoid, numerical_derivative)\n",
    "import numpy as np\n",
    "\n",
    "# sigmoid 함수\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 수치미분 함수\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x + delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x - delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2475adc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] NeuralNetwork (__init__, feed_forward)\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    # 생성자\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes):\n",
    "        \n",
    "        self.__input_nodes = input_nodes   # input_nodes = 784\n",
    "        self.__hidden_nodes = hidden_nodes # hidden_nodes = 1004\n",
    "        self.__output_nodes = output_nodes # output_nodes = 10\n",
    "        \n",
    "        # 2층 hidden layer unit\n",
    "        # 가중치 W, 바이어스 b 초기화\n",
    "        self.__W2 = np.random.rand(self.__input_nodes, self.__hidden_nodes) # W2 = (784 X 100)\n",
    "        self.__b2 = np.random.rand(self.__hidden_nodes) # b2 = (100,)\n",
    "        \n",
    "        # 3층 output layer unit\n",
    "        self.__W3 = np.random.randn(self.__hidden_nodes, self.__output_nodes) # W3 = (100 X 10)\n",
    "        self.__b3 = np.random.rand(self.__output_nodes) # b3 = (10,)\n",
    "        \n",
    "        # 학습률 learning rate 초기화\n",
    "        self.__learning_rate = 1e-4\n",
    "        \n",
    "    # feed forward를 이용하여 입력층에서부터 출력층까지 데이터를 전달하고 손실 함수 값 계산\n",
    "    # loss_val(self) 메소드와 동일한 코드. loss_val(self)은 외부 출력용으로 사용됨\n",
    "    def feed_forward(self):\n",
    "        \n",
    "        delta = 1e-7 # log 무한대 발산 방지\n",
    "        \n",
    "        z1 = np.dot(self.input_data, self.__W2) + self.__b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.__W3) + self.__b3\n",
    "        y = sigmoid(z2)\n",
    "        \n",
    "        # cross-entropy\n",
    "        return -np.sum(self.target_data * np.log(y + delta) + (1 - self.target_data) * np.log((1 - y) + delta))\n",
    "\n",
    "# [2] NeuralNetwork (loss_val)\n",
    "    # 손실 값 계산\n",
    "    def loss_val(self):\n",
    "        \n",
    "        delta = 1e-7 # log 무한대 발산 방지\n",
    "        \n",
    "        z1 = np.dot(self.input_data, self.__W2) + self.__b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.__W3) + self.__b3\n",
    "        y = sigmoid(z2)\n",
    "        \n",
    "        # cross-entropy\n",
    "        return -np.sum(self.target_data * np.log(y + delta) + (1 - self.target_data) * np.log((1 - y) + delta))\n",
    "\n",
    "# [2] NeuralNetwork (train, predict)\n",
    "# input_data : 784 개, target_data : 10개\n",
    "    def train(self, training_data):\n",
    "        \n",
    "        # normalize\n",
    "        self.target_data = np.zeros(self.__output_nodes) + 0.01\n",
    "        self.target_data[int(training_data[0])] = 0.99\n",
    "        \n",
    "        self.input_data = (training_data[1:] / 255.0 * 0.99) + 0.01\n",
    "        \n",
    "        f = lambda x : self.feed_forward()\n",
    "        \n",
    "        self.__W2 -= self.__learning_rate * numerical_derivative(f, self.__W2)\n",
    "        self.__b2 -= self.__learning_rate * numerical_derivative(f, self.__b2)\n",
    "        self.__W3 -= self.__learning_rate * numerical_derivative(f, self.__W3)\n",
    "        self.__b3 -= self.__learning_rate * numerical_derivative(f, self.__b3)\n",
    "        \n",
    "    # query. 즉 미래 값 예측 함수\n",
    "    def predict(self, input_data):\n",
    "        \n",
    "        z1 = np.dot(input_data, self.__W2) + self.__b2\n",
    "        y1 = sigmoid(z1)\n",
    "        \n",
    "        z2 = np.dot(y1, self.__W3) + self.__b3\n",
    "        y = sigmoid(z2)\n",
    "        \n",
    "        predicted_num = np.argmax(y)\n",
    "        \n",
    "        return predicted_num\n",
    "    \n",
    "    # NeuralNetwork (accuracy)\n",
    "    # 정확도 측정함수\n",
    "    def accuracy(self, test_dat):\n",
    "        \n",
    "        matched_list = []\n",
    "        not_matched_list = []\n",
    "        \n",
    "        for index in range(len(test_data)):\n",
    "            \n",
    "            label = int(test_data[index, 0])\n",
    "            \n",
    "            # normalize\n",
    "            data = (test_data[index, 1:] / 255.0 * 0.99) + 0.01\n",
    "            \n",
    "            predicted_num = self.predict(data)\n",
    "            \n",
    "            if label == predicted_num:\n",
    "                matched_list.append(index)\n",
    "            else:\n",
    "                not_matched_list.append(index)\n",
    "                \n",
    "        print(\"Current Accuracy = \", 100 * (len(matched_list) / (len(test_data))), \"%\")\n",
    "        \n",
    "        return matched_list, not_matched_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81407745",
   "metadata": {},
   "source": [
    "검증코드 - MNIST (필기체 숫자 인식)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] usage (data feeding, learning process)\n",
    "input_nodes = 784\n",
    "hidden_nodes = 100\n",
    "output_nodes = 10\n",
    "\n",
    "nn = NeuralNetwork(input_nodes, hidden_nodes, output_nodes)\n",
    "\n",
    "for step in range(30001): # 전체 training data 중 50 %\n",
    "    \n",
    "    # 총 60,000개의 training data 가운데 random 하게 30,000개 선택\n",
    "    index = np.random.randint(0, len(training_data) - 1)\n",
    "    \n",
    "    nn.train(training_data[index])\n",
    "    \n",
    "    if step % 400 == 0:\n",
    "        print(\"step =\", step, \", loss_val\", nn.loss_val())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b665ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuray 계산\n",
    "\n",
    "nn.accuracy(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
