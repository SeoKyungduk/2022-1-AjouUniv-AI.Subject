{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0fd187",
   "metadata": {},
   "source": [
    "# 11_Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd3280e",
   "metadata": {},
   "source": [
    "Simple logistic regression (classification) - example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "10828498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape =  (10, 1) , t_data.shape =  (10, 1)\n"
     ]
    }
   ],
   "source": [
    "# [1] 학습데이터 (training data) 준비\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]).reshape(10, 1)\n",
    "t_data = np.array([0, 0, 0, 0,  0,  0,  1,  1,  1,  1]).reshape(10, 1)\n",
    "\n",
    "print(\"x_data.shape = \", x_data.shape, \", t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3db5ecfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.89044891]] , W.shape =  (1, 1) , b =  [0.80677837] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "# [2] 임의의 직선 z = Wx + b 정의 (임의의 값으로 가중치 W, 바이어스 b 초기화)\n",
    "W = np.random.rand(1, 1)\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e25dbb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] 손실함수 E(W, b) 정의\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def loss_func(x, t):\n",
    "    \n",
    "    delta = 1e-7 # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum(t * np.log(y + delta) + (1 - t) * np.log((1 - y) + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4774d6c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] 수치미분 numerical_derivative 및 utility 함수 정의\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x + delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x - delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff40e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수 값 계산 함수\n",
    "# 입력변수 x, t : numpy type\n",
    "def error_val(x, t):\n",
    "    delta = 1e-7 # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum(t * np.log(y + delta) + (1 - t)*np.log(1 - y) + delta)\n",
    "\n",
    "# 학습을 마친 후, 임의 데이터에 대해 미래 값 예측 함수\n",
    "# 입력변수 x : numpy\n",
    "def predict(x):\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y > 0.5:\n",
    "        result = 1 # True\n",
    "    else:\n",
    "        result = 0 # False\n",
    "    \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6659b77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  42.3271792565909 Initial W =  [[0.89044891]] \n",
      " , b =  [0.80677837]\n",
      "step =  0 error value =  24.67952936471593 W =  [[0.47386629]] , b =  [0.7492991]\n",
      "step =  400 error value =  2.8161069258081373 W =  [[0.27761678]] , b =  [-4.10152596]\n",
      "step =  800 error value =  1.7838884755451239 W =  [[0.45331488]] , b =  [-5.64042455]\n",
      "step =  1200 error value =  1.5180178433967753 W =  [[0.5306688]] , b =  [-6.67044374]\n",
      "step =  1600 error value =  1.3524887523611018 W =  [[0.59193391]] , b =  [-7.48399899]\n",
      "step =  2000 error value =  1.236002015941317 W =  [[0.64345523]] , b =  [-8.16666804]\n",
      "step =  2400 error value =  1.1478327595874274 W =  [[0.68836114]] , b =  [-8.7606246]\n",
      "step =  2800 error value =  1.077796808981543 W =  [[0.72844154]] , b =  [-9.28997746]\n",
      "step =  3200 error value =  1.0202236237666589 W =  [[0.76482409]] , b =  [-9.76989876]\n",
      "step =  3600 error value =  0.9716683003743014 W =  [[0.79826891]] , b =  [-10.21060447]\n",
      "step =  4000 error value =  0.9298987273762745 W =  [[0.82931482]] , b =  [-10.61932791]\n",
      "step =  4400 error value =  0.8933949974244215 W =  [[0.85835887]] , b =  [-11.00139356]\n",
      "step =  4800 error value =  0.8610805098180114 W =  [[0.88570283]] , b =  [-11.3608441]\n",
      "step =  5200 error value =  0.8321677746958602 W =  [[0.91158193]] , b =  [-11.70082754]\n",
      "step =  5600 error value =  0.8060652035323724 W =  [[0.93618342]] , b =  [-12.0238473]\n",
      "step =  6000 error value =  0.7823182601789948 W =  [[0.95965899]] , b =  [-12.33192987]\n",
      "step =  6400 error value =  0.7605709238618307 W =  [[0.98213342]] , b =  [-12.6267408]\n",
      "step =  6800 error value =  0.7405396558885694 W =  [[1.00371071]] , b =  [-12.90966716]\n",
      "step =  7200 error value =  0.72199533482977 W =  [[1.02447855]] , b =  [-13.18187745]\n",
      "step =  7600 error value =  0.704750424522983 W =  [[1.0445116]] , b =  [-13.44436613]\n",
      "step =  8000 error value =  0.6886496697121973 W =  [[1.06387401]] , b =  [-13.69798717]\n",
      "step =  8400 error value =  0.6735632254240128 W =  [[1.08262139]] , b =  [-13.94347991]\n",
      "step =  8800 error value =  0.6593815002541642 W =  [[1.10080221]] , b =  [-14.18148905]\n",
      "step =  9200 error value =  0.6460112290362561 W =  [[1.11845909]] , b =  [-14.41258052]\n",
      "step =  9600 error value =  0.6333724420576027 W =  [[1.13562964]] , b =  [-14.63725406]\n",
      "step =  10000 error value =  0.6213960979604224 W =  [[1.15234731]] , b =  [-14.8559534]\n"
     ]
    }
   ],
   "source": [
    "# [5] 학습율 (learning rate) 초기화 및 손실함수가 최소가 될 때까지 W, b 업데이트\n",
    "learning_rate = 1e-2 # 발산하는 경우, 1e-3 ~ 1e-6 등으로 바꾸어서 실행\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data) # f(x) = loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(10001):\n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "498d8315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.12075526e-05]] 0\n"
     ]
    }
   ],
   "source": [
    "# [6] 학습 결과 (오차 함수 값 감소 확인) 및 입력 3시간, 17시간에 대한 미래 값 Fail / Pass 예측\n",
    "(real_val, logical_val) = predict(3)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a47df3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99128495]] 1\n"
     ]
    }
   ],
   "source": [
    "(real_val, logical_val) = predict(17)\n",
    "\n",
    "print(real_val, logical_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7325b61a",
   "metadata": {},
   "source": [
    "Multi-variable logistic regression (classification) - overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3867911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.ndim =  2 , x_data.shape =  (9, 2)\n",
      "t_data.ndim =  2 , t_data.shape =  (9, 1)\n"
     ]
    }
   ],
   "source": [
    "# [1] 학습데이터 (training data) 준비\n",
    "import numpy as np\n",
    "\n",
    "x_data = np.array([[2, 4], [4, 11], [6, 6], [8, 5], [10, 7], [12, 16], [14, 8], [16, 3], [18, 7]])\n",
    "t_data = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1]).reshape(9, 1)\n",
    "\n",
    "# 데이터 차원 및 shape 확인\n",
    "print(\"x_data.ndim = \", x_data.ndim, \", x_data.shape = \", x_data.shape)\n",
    "print(\"t_data.ndim = \", t_data.ndim, \", t_data.shape = \", t_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8007ada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W =  [[0.86802812]\n",
      " [0.21258245]] , W.shape =  (2, 1) , b =  [0.76576268] , b.shape =  (1,)\n"
     ]
    }
   ],
   "source": [
    "# [2] 임의의 직선 z= W1x1 + W2x2 + b 정의 (가중치 W, 바이어스 b 초기화)\n",
    "W = np.random.rand(2, 1) # 2 X 1 행렬\n",
    "b = np.random.rand(1)\n",
    "print(\"W = \", W, \", W.shape = \", W.shape, \", b = \", b, \", b.shape = \", b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8e0d09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [3] 손실함수 E(W, b) 정의\n",
    "# classification 이므로 출력함수로 sigmoid 정의\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# 최종출력은 y = sigmoid(Wx + b)이며, 손실함수는 cross-entropy로 나타냄\n",
    "\n",
    "def loss_func(x, t):\n",
    "    \n",
    "    delta = 1e-7 # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum(t * np.log(y + delta) + (1 - t) * np.log((1 - y) + delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "2f6eb36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [4] 수치미분 numerical_derivative 및 utility 함수 정의\n",
    "def numerical_derivative(f, x):\n",
    "    delta_x = 1e-4 # 0.0001\n",
    "    grad = np.zeros_like(x)\n",
    "    \n",
    "    it = np.nditer(x, flags = ['multi_index'], op_flags = ['readwrite'])\n",
    "    \n",
    "    while not it.finished:\n",
    "        idx = it.multi_index\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = float(tmp_val) + delta_x\n",
    "        fx1 = f(x) # f(x + delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val - delta_x\n",
    "        fx2 = f(x) # f(x - delta_x)\n",
    "        grad[idx] = (fx1 - fx2) / (2 * delta_x)\n",
    "        \n",
    "        x[idx] = tmp_val\n",
    "        it.iternext()\n",
    "        \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3c566c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_val(x, t):\n",
    "    delta = 1e-7 # log 무한대 발산 방지\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    # cross-entropy\n",
    "    return -np.sum(t * np.log(y + delta) + (1 - t)*np.log(1 - y) + delta)\n",
    "\n",
    "def predict(x):\n",
    "    \n",
    "    z = np.dot(x, W) + b\n",
    "    y = sigmoid(z)\n",
    "    \n",
    "    if y > 0.5:\n",
    "        result = 1 # True\n",
    "    else:\n",
    "        result = 0 # False\n",
    "    \n",
    "    return y, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b515793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial error value =  25.98744173377466 Initial W =  [[0.86802812]\n",
      " [0.21258245]] \n",
      " , b =  [0.76576268]\n",
      "step =  0 error value =  15.30814350056577 W =  [[ 0.66888018]\n",
      " [-0.04581111]] , b =  [0.72769377]\n",
      "step =  400 error value =  2.319783837942666 W =  [[ 0.41456134]\n",
      " [-0.09052032]] , b =  [-2.53479398]\n",
      "step =  800 error value =  1.6091545856036256 W =  [[ 0.53213194]\n",
      " [-0.02824481]] , b =  [-4.20758883]\n",
      "step =  1200 error value =  1.2895214191339162 W =  [[0.62015327]\n",
      " [0.00778712]] , b =  [-5.33425143]\n",
      "step =  1600 error value =  1.104218097490032 W =  [[0.6910408 ]\n",
      " [0.03329607]] , b =  [-6.1930682]\n",
      "step =  2000 error value =  0.9808970268411208 W =  [[0.75070232]\n",
      " [0.05353171]] , b =  [-6.89390948]\n",
      "step =  2400 error value =  0.8914288933175842 W =  [[0.80238004]\n",
      " [0.07080307]] , b =  [-7.49090051]\n",
      "step =  2800 error value =  0.8226006371671412 W =  [[0.84804696]\n",
      " [0.08629783]] , b =  [-8.01451671]\n",
      "step =  3200 error value =  0.7673732440511035 W =  [[0.88899716]\n",
      " [0.10069005]] , b =  [-8.48353722]\n",
      "step =  3600 error value =  0.7216418319678457 W =  [[0.92612911]\n",
      " [0.11438755]] , b =  [-8.91031771]\n",
      "step =  4000 error value =  0.6828433467177063 W =  [[0.96009544]\n",
      " [0.12764688]] , b =  [-9.30340414]\n",
      "step =  4400 error value =  0.6492896023912619 W =  [[0.99138833]\n",
      " [0.1406322 ]] , b =  [-9.66894492]\n",
      "step =  4800 error value =  0.6198199244032058 W =  [[1.02039087]\n",
      " [0.15344781]] , b =  [-10.01150649]\n",
      "step =  5200 error value =  0.5936077799098737 W =  [[1.04740955]\n",
      " [0.16615751]] , b =  [-10.3345702]\n",
      "step =  5600 error value =  0.5700471022079067 W =  [[1.07269524]\n",
      " [0.17879681]] , b =  [-10.64084875]\n",
      "step =  6000 error value =  0.5486823540016078 W =  [[1.09645739]\n",
      " [0.1913813 ]] , b =  [-10.93249532]\n",
      "step =  6400 error value =  0.5291638064245404 W =  [[1.11887348]\n",
      " [0.20391255]] , b =  [-11.21124626]\n",
      "step =  6800 error value =  0.5112179775147266 W =  [[1.14009573]\n",
      " [0.21638265]] , b =  [-11.4785212]\n",
      "step =  7200 error value =  0.4946275211465472 W =  [[1.16025572]\n",
      " [0.22877769]] , b =  [-11.73549507]\n",
      "step =  7600 error value =  0.4792171978878016 W =  [[1.17946782]\n",
      " [0.24108042]] , b =  [-11.98315093]\n",
      "step =  8000 error value =  0.46484387182932424 W =  [[1.1978317 ]\n",
      " [0.25327234]] , b =  [-12.22231949]\n",
      "step =  8400 error value =  0.4513892402027106 W =  [[1.21543432]\n",
      " [0.2653352 ]] , b =  [-12.45370926]\n",
      "step =  8800 error value =  0.43875445997282453 W =  [[1.23235157]\n",
      " [0.27725206]] , b =  [-12.67792967]\n",
      "step =  9200 error value =  0.42685611765859044 W =  [[1.24864966]\n",
      " [0.28900796]] , b =  [-12.89550916]\n",
      "step =  9600 error value =  0.4156231671148804 W =  [[1.2643863 ]\n",
      " [0.30059027]] , b =  [-13.10690948]\n",
      "step =  10000 error value =  0.4049945756736519 W =  [[1.27961178]\n",
      " [0.31198884]] , b =  [-13.31253697]\n",
      "step =  10400 error value =  0.3949174957015408 W =  [[1.29436995]\n",
      " [0.32319588]] , b =  [-13.51275165]\n",
      "step =  10800 error value =  0.3853458305169278 W =  [[1.30869908]\n",
      " [0.3342059 ]] , b =  [-13.70787456]\n",
      "step =  11200 error value =  0.37623909941533246 W =  [[1.32263257]\n",
      " [0.34501542]] , b =  [-13.89819366]\n",
      "step =  11600 error value =  0.36756153170321376 W =  [[1.3361997 ]\n",
      " [0.35562272]] , b =  [-14.08396871]\n",
      "step =  12000 error value =  0.35928133758142894 W =  [[1.34942615]\n",
      " [0.3660276 ]] , b =  [-14.26543524]\n",
      "step =  12400 error value =  0.3513701166980722 W =  [[1.36233455]\n",
      " [0.37623111]] , b =  [-14.44280783]\n",
      "step =  12800 error value =  0.34380237468673913 W =  [[1.37494492]\n",
      " [0.38623532]] , b =  [-14.61628285]\n",
      "step =  13200 error value =  0.3365551250271091 W =  [[1.38727501]\n",
      " [0.39604312]] , b =  [-14.78604072]\n",
      "step =  13600 error value =  0.32960755880106457 W =  [[1.39934068]\n",
      " [0.40565802]] , b =  [-14.95224786]\n",
      "step =  14000 error value =  0.32294076885338896 W =  [[1.4111561 ]\n",
      " [0.41508403]] , b =  [-15.11505826]\n",
      "step =  14400 error value =  0.3165375178443172 W =  [[1.42273406]\n",
      " [0.42432548]] , b =  [-15.27461489]\n",
      "step =  14800 error value =  0.31038204195075675 W =  [[1.4340861 ]\n",
      " [0.43338698]] , b =  [-15.43105087]\n",
      "step =  15200 error value =  0.30445988371193833 W =  [[1.44522271]\n",
      " [0.44227326]] , b =  [-15.58449045]\n",
      "step =  15600 error value =  0.2987577488553182 W =  [[1.45615346]\n",
      " [0.45098915]] , b =  [-15.7350499]\n",
      "step =  16000 error value =  0.29326338297823773 W =  [[1.46688712]\n",
      " [0.4595395 ]] , b =  [-15.88283826]\n",
      "step =  16400 error value =  0.2879654647705341 W =  [[1.47743176]\n",
      " [0.46792915]] , b =  [-16.02795801]\n",
      "step =  16800 error value =  0.2828535130987715 W =  [[1.48779483]\n",
      " [0.47616287]] , b =  [-16.17050563]\n",
      "step =  17200 error value =  0.2779178057729017 W =  [[1.49798323]\n",
      " [0.48424536]] , b =  [-16.31057212]\n",
      "step =  17600 error value =  0.27314930821321765 W =  [[1.5080034 ]\n",
      " [0.49218123]] , b =  [-16.44824344]\n",
      "step =  18000 error value =  0.2685396105515538 W =  [[1.51786133]\n",
      " [0.49997496]] , b =  [-16.58360094]\n",
      "step =  18400 error value =  0.2640808719541506 W =  [[1.52756264]\n",
      " [0.5076309 ]] , b =  [-16.71672167]\n",
      "step =  18800 error value =  0.2597657711573691 W =  [[1.53711258]\n",
      " [0.5151533 ]] , b =  [-16.84767873]\n",
      "step =  19200 error value =  0.2555874623732955 W =  [[1.54651612]\n",
      " [0.52254623]] , b =  [-16.97654155]\n",
      "step =  19600 error value =  0.2515395358565583 W =  [[1.55577792]\n",
      " [0.52981365]] , b =  [-17.10337617]\n",
      "step =  20000 error value =  0.2476159825337711 W =  [[1.56490241]\n",
      " [0.53695939]] , b =  [-17.22824544]\n",
      "step =  20400 error value =  0.24381116218801074 W =  [[1.57389377]\n",
      " [0.54398711]] , b =  [-17.35120924]\n",
      "step =  20800 error value =  0.24011977476538962 W =  [[1.58275597]\n",
      " [0.55090036]] , b =  [-17.4723247]\n",
      "step =  21200 error value =  0.23653683443311727 W =  [[1.59149277]\n",
      " [0.55770255]] , b =  [-17.59164636]\n",
      "step =  21600 error value =  0.23305764607052082 W =  [[1.60010777]\n",
      " [0.56439698]] , b =  [-17.70922631]\n",
      "step =  22000 error value =  0.22967778391797866 W =  [[1.60860438]\n",
      " [0.57098678]] , b =  [-17.8251144]\n",
      "step =  22400 error value =  0.22639307214534424 W =  [[1.61698588]\n",
      " [0.57747502]] , b =  [-17.9393583]\n",
      "step =  22800 error value =  0.22319956713292816 W =  [[1.62525538]\n",
      " [0.5838646 ]] , b =  [-18.05200369]\n",
      "step =  23200 error value =  0.2200935412837608 W =  [[1.63341586]\n",
      " [0.59015834]] , b =  [-18.16309433]\n",
      "step =  23600 error value =  0.21707146820914014 W =  [[1.64147019]\n",
      " [0.59635894]] , b =  [-18.27267219]\n",
      "step =  24000 error value =  0.21413000914815755 W =  [[1.64942111]\n",
      " [0.602469  ]] , b =  [-18.38077757]\n",
      "step =  24400 error value =  0.21126600049885239 W =  [[1.65727124]\n",
      " [0.60849102]] , b =  [-18.48744915]\n",
      "step =  24800 error value =  0.20847644235254065 W =  [[1.66502311]\n",
      " [0.6144274 ]] , b =  [-18.59272408]\n",
      "step =  25200 error value =  0.20575848793563226 W =  [[1.67267914]\n",
      " [0.62028046]] , b =  [-18.69663811]\n",
      "step =  25600 error value =  0.20310943387365235 W =  [[1.68024168]\n",
      " [0.62605243]] , b =  [-18.7992256]\n",
      "step =  26000 error value =  0.20052671120176432 W =  [[1.68771296]\n",
      " [0.63174545]] , b =  [-18.90051965]\n",
      "step =  26400 error value =  0.1980078770539582 W =  [[1.69509515]\n",
      " [0.63736158]] , b =  [-19.0005521]\n",
      "step =  26800 error value =  0.19555060697060722 W =  [[1.70239034]\n",
      " [0.64290281]] , b =  [-19.09935364]\n",
      "step =  27200 error value =  0.19315268777002473 W =  [[1.70960053]\n",
      " [0.64837106]] , b =  [-19.19695387]\n",
      "step =  27600 error value =  0.1908120109353715 W =  [[1.71672768]\n",
      " [0.65376818]] , b =  [-19.2933813]\n",
      "step =  28000 error value =  0.18852656647308794 W =  [[1.72377364]\n",
      " [0.65909594]] , b =  [-19.38866346]\n",
      "step =  28400 error value =  0.18629443720338504 W =  [[1.73074024]\n",
      " [0.66435606]] , b =  [-19.48282693]\n",
      "step =  28800 error value =  0.18411379344719236 W =  [[1.73762921]\n",
      " [0.6695502 ]] , b =  [-19.57589734]\n",
      "step =  29200 error value =  0.18198288807696475 W =  [[1.74444226]\n",
      " [0.67467995]] , b =  [-19.6678995]\n",
      "step =  29600 error value =  0.17990005190268626 W =  [[1.75118101]\n",
      " [0.67974685]] , b =  [-19.75885734]\n",
      "step =  30000 error value =  0.17786368936608796 W =  [[1.75784705]\n",
      " [0.68475239]] , b =  [-19.84879403]\n",
      "step =  30400 error value =  0.17587227451909473 W =  [[1.76444191]\n",
      " [0.68969802]] , b =  [-19.93773196]\n",
      "step =  30800 error value =  0.17392434726478048 W =  [[1.77096708]\n",
      " [0.69458512]] , b =  [-20.0256928]\n",
      "step =  31200 error value =  0.1720185098405541 W =  [[1.777424  ]\n",
      " [0.69941502]] , b =  [-20.11269753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  31600 error value =  0.17015342352555957 W =  [[1.78381405]\n",
      " [0.70418904]] , b =  [-20.19876645]\n",
      "step =  32000 error value =  0.16832780555554278 W =  [[1.79013858]\n",
      " [0.70890843]] , b =  [-20.28391925]\n",
      "step =  32400 error value =  0.16654042622993812 W =  [[1.79639892]\n",
      " [0.71357439]] , b =  [-20.36817497]\n",
      "step =  32800 error value =  0.16479010619729728 W =  [[1.80259633]\n",
      " [0.71818811]] , b =  [-20.4515521]\n",
      "step =  33200 error value =  0.1630757139061897 W =  [[1.80873205]\n",
      " [0.72275072]] , b =  [-20.53406854]\n",
      "step =  33600 error value =  0.1613961632098672 W =  [[1.81480727]\n",
      " [0.72726332]] , b =  [-20.61574167]\n",
      "step =  34000 error value =  0.15975041111393443 W =  [[1.82082316]\n",
      " [0.73172698]] , b =  [-20.69658833]\n",
      "step =  34400 error value =  0.1581374556570462 W =  [[1.82678085]\n",
      " [0.73614274]] , b =  [-20.7766249]\n",
      "step =  34800 error value =  0.1565563339155439 W =  [[1.83268143]\n",
      " [0.74051159]] , b =  [-20.85586724]\n",
      "step =  35200 error value =  0.15500612012360845 W =  [[1.83852598]\n",
      " [0.74483451]] , b =  [-20.93433078]\n",
      "step =  35600 error value =  0.15348592390113258 W =  [[1.84431554]\n",
      " [0.74911243]] , b =  [-21.01203049]\n",
      "step =  36000 error value =  0.15199488858216703 W =  [[1.85005111]\n",
      " [0.75334628]] , b =  [-21.08898092]\n",
      "step =  36400 error value =  0.1505321896373254 W =  [[1.85573368]\n",
      " [0.75753694]] , b =  [-21.16519621]\n",
      "step =  36800 error value =  0.14909703318400203 W =  [[1.8613642 ]\n",
      " [0.76168526]] , b =  [-21.24069011]\n",
      "step =  37200 error value =  0.14768865457876337 W =  [[1.86694361]\n",
      " [0.76579208]] , b =  [-21.31547598]\n",
      "step =  37600 error value =  0.14630631708660408 W =  [[1.87247281]\n",
      " [0.76985822]] , b =  [-21.38956684]\n",
      "step =  38000 error value =  0.14494931062224453 W =  [[1.87795268]\n",
      " [0.77388446]] , b =  [-21.46297532]\n",
      "step =  38400 error value =  0.14361695055893928 W =  [[1.88338408]\n",
      " [0.77787156]] , b =  [-21.53571373]\n",
      "step =  38800 error value =  0.1423085766006114 W =  [[1.88876785]\n",
      " [0.78182027]] , b =  [-21.60779406]\n",
      "step =  39200 error value =  0.14102355171333253 W =  [[1.89410481]\n",
      " [0.78573132]] , b =  [-21.67922797]\n",
      "step =  39600 error value =  0.1397612611126979 W =  [[1.89939576]\n",
      " [0.7896054 ]] , b =  [-21.75002681]\n",
      "step =  40000 error value =  0.13852111130351624 W =  [[1.90464145]\n",
      " [0.7934432 ]] , b =  [-21.82020166]\n",
      "step =  40400 error value =  0.13730252916878932 W =  [[1.90984266]\n",
      " [0.79724539]] , b =  [-21.88976328]\n",
      "step =  40800 error value =  0.13610496110508077 W =  [[1.91500013]\n",
      " [0.8010126 ]] , b =  [-21.95872219]\n",
      "step =  41200 error value =  0.13492787220144328 W =  [[1.92011456]\n",
      " [0.80474548]] , b =  [-22.02708862]\n",
      "step =  41600 error value =  0.13377074545941697 W =  [[1.92518666]\n",
      " [0.80844463]] , b =  [-22.09487255]\n",
      "step =  42000 error value =  0.13263308105174978 W =  [[1.93021712]\n",
      " [0.81211065]] , b =  [-22.16208371]\n",
      "step =  42400 error value =  0.13151439561755535 W =  [[1.93520661]\n",
      " [0.81574413]] , b =  [-22.2287316]\n",
      "step =  42800 error value =  0.13041422159186092 W =  [[1.94015578]\n",
      " [0.81934562]] , b =  [-22.29482547]\n",
      "step =  43200 error value =  0.12933210656757071 W =  [[1.94506526]\n",
      " [0.82291568]] , b =  [-22.36037436]\n",
      "step =  43600 error value =  0.12826761268812722 W =  [[1.94993568]\n",
      " [0.82645485]] , b =  [-22.42538709]\n",
      "step =  44000 error value =  0.127220316069061 W =  [[1.95476765]\n",
      " [0.82996365]] , b =  [-22.48987226]\n",
      "step =  44400 error value =  0.12618980624684836 W =  [[1.95956177]\n",
      " [0.83344259]] , b =  [-22.55383827]\n",
      "step =  44800 error value =  0.12517568565363638 W =  [[1.9643186 ]\n",
      " [0.83689218]] , b =  [-22.61729332]\n",
      "step =  45200 error value =  0.12417756911640353 W =  [[1.96903873]\n",
      " [0.84031289]] , b =  [-22.68024544]\n",
      "step =  45600 error value =  0.12319508337924749 W =  [[1.97372269]\n",
      " [0.8437052 ]] , b =  [-22.74270244]\n",
      "step =  46000 error value =  0.12222786664753064 W =  [[1.97837105]\n",
      " [0.84706958]] , b =  [-22.80467197]\n",
      "step =  46400 error value =  0.1212755681527482 W =  [[1.98298433]\n",
      " [0.85040648]] , b =  [-22.8661615]\n",
      "step =  46800 error value =  0.12033784773706982 W =  [[1.98756304]\n",
      " [0.85371633]] , b =  [-22.92717834]\n",
      "step =  47200 error value =  0.11941437545646374 W =  [[1.9921077 ]\n",
      " [0.85699957]] , b =  [-22.98772961]\n",
      "step =  47600 error value =  0.11850483120145536 W =  [[1.99661879]\n",
      " [0.86025661]] , b =  [-23.04782231]\n",
      "step =  48000 error value =  0.11760890433465784 W =  [[2.00109682]\n",
      " [0.86348787]] , b =  [-23.10746325]\n",
      "step =  48400 error value =  0.11672629334415159 W =  [[2.00554224]\n",
      " [0.86669376]] , b =  [-23.16665911]\n",
      "step =  48800 error value =  0.11585670551193154 W =  [[2.00995554]\n",
      " [0.86987465]] , b =  [-23.22541642]\n",
      "step =  49200 error value =  0.11499985659674344 W =  [[2.01433715]\n",
      " [0.87303093]] , b =  [-23.28374155]\n",
      "step =  49600 error value =  0.11415547053042432 W =  [[2.01868754]\n",
      " [0.87616298]] , b =  [-23.34164076]\n",
      "step =  50000 error value =  0.113323279127249 W =  [[2.02300713]\n",
      " [0.87927117]] , b =  [-23.39912017]\n",
      "step =  50400 error value =  0.11250302180553187 W =  [[2.02729635]\n",
      " [0.88235584]] , b =  [-23.45618575]\n",
      "step =  50800 error value =  0.11169444532089967 W =  [[2.03155562]\n",
      " [0.88541735]] , b =  [-23.51284337]\n",
      "step =  51200 error value =  0.11089730351075008 W =  [[2.03578536]\n",
      " [0.88845605]] , b =  [-23.56909876]\n",
      "step =  51600 error value =  0.11011135704924013 W =  [[2.03998596]\n",
      " [0.89147226]] , b =  [-23.62495754]\n",
      "step =  52000 error value =  0.10933637321234603 W =  [[2.04415782]\n",
      " [0.89446632]] , b =  [-23.6804252]\n",
      "step =  52400 error value =  0.10857212565257565 W =  [[2.04830133]\n",
      " [0.89743854]] , b =  [-23.73550714]\n",
      "step =  52800 error value =  0.10781839418275592 W =  [[2.05241686]\n",
      " [0.90038923]] , b =  [-23.79020864]\n",
      "step =  53200 error value =  0.10707496456861276 W =  [[2.05650478]\n",
      " [0.90331871]] , b =  [-23.84453486]\n",
      "step =  53600 error value =  0.10634162832958043 W =  [[2.06056546]\n",
      " [0.90622727]] , b =  [-23.89849086]\n",
      "step =  54000 error value =  0.10561818254760418 W =  [[2.06459925]\n",
      " [0.90911521]] , b =  [-23.95208162]\n",
      "step =  54400 error value =  0.10490442968342488 W =  [[2.06860651]\n",
      " [0.91198281]] , b =  [-24.00531201]\n",
      "step =  54800 error value =  0.10420017740015944 W =  [[2.07258758]\n",
      " [0.91483036]] , b =  [-24.05818678]\n",
      "step =  55200 error value =  0.10350523839370392 W =  [[2.07654279]\n",
      " [0.91765814]] , b =  [-24.11071062]\n",
      "step =  55600 error value =  0.10281943022974376 W =  [[2.08047247]\n",
      " [0.92046641]] , b =  [-24.16288812]\n",
      "step =  56000 error value =  0.10214257518702928 W =  [[2.08437695]\n",
      " [0.92325543]] , b =  [-24.21472376]\n",
      "step =  56400 error value =  0.10147450010665726 W =  [[2.08825655]\n",
      " [0.92602548]] , b =  [-24.26622197]\n",
      "step =  56800 error value =  0.10081503624707132 W =  [[2.09211157]\n",
      " [0.92877679]] , b =  [-24.31738707]\n",
      "step =  57200 error value =  0.1001640191445676 W =  [[2.09594233]\n",
      " [0.93150963]] , b =  [-24.3682233]\n",
      "step =  57600 error value =  0.09952128847901111 W =  [[2.09974912]\n",
      " [0.93422423]] , b =  [-24.41873482]\n",
      "step =  58000 error value =  0.09888668794460835 W =  [[2.10353224]\n",
      " [0.93692084]] , b =  [-24.46892572]\n",
      "step =  58400 error value =  0.09826006512541025 W =  [[2.10729198]\n",
      " [0.93959969]] , b =  [-24.51880002]\n",
      "step =  58800 error value =  0.09764127137548204 W =  [[2.11102861]\n",
      " [0.94226101]] , b =  [-24.56836164]\n",
      "step =  59200 error value =  0.09703016170342213 W =  [[2.11474244]\n",
      " [0.94490503]] , b =  [-24.61761445]\n",
      "step =  59600 error value =  0.09642659466109252 W =  [[2.11843371]\n",
      " [0.94753196]] , b =  [-24.66656224]\n",
      "step =  60000 error value =  0.09583043223637841 W =  [[2.12210271]\n",
      " [0.95014204]] , b =  [-24.71520874]\n",
      "step =  60400 error value =  0.09524153974982735 W =  [[2.12574971]\n",
      " [0.95273546]] , b =  [-24.7635576]\n",
      "step =  60800 error value =  0.09465978575498793 W =  [[2.12937495]\n",
      " [0.95531244]] , b =  [-24.8116124]\n",
      "step =  61200 error value =  0.09408504194226011 W =  [[2.13297869]\n",
      " [0.95787318]] , b =  [-24.85937668]\n",
      "step =  61600 error value =  0.09351718304619346 W =  [[2.1365612 ]\n",
      " [0.96041789]] , b =  [-24.9068539]\n",
      "step =  62000 error value =  0.09295608675601426 W =  [[2.1401227 ]\n",
      " [0.96294677]] , b =  [-24.95404746]\n",
      "step =  62400 error value =  0.09240163362929289 W =  [[2.14366345]\n",
      " [0.96546   ]] , b =  [-25.0009607]\n",
      "step =  62800 error value =  0.09185370700862026 W =  [[2.14718369]\n",
      " [0.96795778]] , b =  [-25.0475969]\n",
      "step =  63200 error value =  0.09131219294115182 W =  [[2.15068364]\n",
      " [0.9704403 ]] , b =  [-25.0939593]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step =  63600 error value =  0.09077698010093695 W =  [[2.15416353]\n",
      " [0.97290774]] , b =  [-25.14005106]\n",
      "step =  64000 error value =  0.09024795971387249 W =  [[2.15762361]\n",
      " [0.97536028]] , b =  [-25.1858753]\n",
      "step =  64400 error value =  0.08972502548523373 W =  [[2.16106408]\n",
      " [0.9777981 ]] , b =  [-25.23143508]\n",
      "step =  64800 error value =  0.08920807352967236 W =  [[2.16448516]\n",
      " [0.98022137]] , b =  [-25.27673342]\n",
      "step =  65200 error value =  0.08869700230349632 W =  [[2.16788707]\n",
      " [0.98263026]] , b =  [-25.32177327]\n",
      "step =  65600 error value =  0.08819171253929084 W =  [[2.17127003]\n",
      " [0.98502495]] , b =  [-25.36655754]\n",
      "step =  66000 error value =  0.0876921071826855 W =  [[2.17463424]\n",
      " [0.98740559]] , b =  [-25.4110891]\n",
      "step =  66400 error value =  0.08719809133120736 W =  [[2.1779799 ]\n",
      " [0.98977235]] , b =  [-25.45537076]\n",
      "step =  66800 error value =  0.086709572175145 W =  [[2.18130722]\n",
      " [0.9921254 ]] , b =  [-25.49940529]\n",
      "step =  67200 error value =  0.08622645894035737 W =  [[2.18461639]\n",
      " [0.99446488]] , b =  [-25.54319541]\n",
      "step =  67600 error value =  0.08574866283292049 W =  [[2.18790762]\n",
      " [0.99679095]] , b =  [-25.5867438]\n",
      "step =  68000 error value =  0.08527609698561177 W =  [[2.19118109]\n",
      " [0.99910376]] , b =  [-25.63005309]\n",
      "step =  68400 error value =  0.08480867640606521 W =  [[2.19443698]\n",
      " [1.00140346]] , b =  [-25.67312588]\n",
      "step =  68800 error value =  0.08434631792661568 W =  [[2.1976755 ]\n",
      " [1.00369021]] , b =  [-25.71596471]\n",
      "step =  69200 error value =  0.08388894015574894 W =  [[2.20089682]\n",
      " [1.00596413]] , b =  [-25.75857209]\n",
      "step =  69600 error value =  0.083436463431064 W =  [[2.20410111]\n",
      " [1.00822538]] , b =  [-25.8009505]\n",
      "step =  70000 error value =  0.08298880977373467 W =  [[2.20728857]\n",
      " [1.01047409]] , b =  [-25.84310236]\n",
      "step =  70400 error value =  0.08254590284439761 W =  [[2.21045935]\n",
      " [1.01271041]] , b =  [-25.88503006]\n",
      "step =  70800 error value =  0.08210766790042211 W =  [[2.21361365]\n",
      " [1.01493446]] , b =  [-25.92673597]\n",
      "step =  71200 error value =  0.08167403175447835 W =  [[2.21675161]\n",
      " [1.01714638]] , b =  [-25.96822239]\n",
      "step =  71600 error value =  0.08124492273444016 W =  [[2.21987342]\n",
      " [1.0193463 ]] , b =  [-26.00949161]\n",
      "step =  72000 error value =  0.08082027064446465 W =  [[2.22297923]\n",
      " [1.02153435]] , b =  [-26.05054587]\n",
      "step =  72400 error value =  0.08040000672729603 W =  [[2.2260692 ]\n",
      " [1.02371065]] , b =  [-26.0913874]\n",
      "step =  72800 error value =  0.07998406362768848 W =  [[2.22914351]\n",
      " [1.02587533]] , b =  [-26.13201835]\n",
      "step =  73200 error value =  0.07957237535697792 W =  [[2.23220229]\n",
      " [1.02802851]] , b =  [-26.17244089]\n",
      "step =  73600 error value =  0.07916487725868601 W =  [[2.23524572]\n",
      " [1.03017032]] , b =  [-26.21265712]\n",
      "step =  74000 error value =  0.07876150597514478 W =  [[2.23827393]\n",
      " [1.03230086]] , b =  [-26.25266912]\n",
      "step =  74400 error value =  0.07836219941516968 W =  [[2.24128709]\n",
      " [1.03442027]] , b =  [-26.29247895]\n",
      "step =  74800 error value =  0.07796689672264079 W =  [[2.24428533]\n",
      " [1.03652865]] , b =  [-26.33208862]\n",
      "step =  75200 error value =  0.07757553824603146 W =  [[2.2472688 ]\n",
      " [1.03862611]] , b =  [-26.37150012]\n",
      "step =  75600 error value =  0.0771880655088328 W =  [[2.25023766]\n",
      " [1.04071278]] , b =  [-26.41071541]\n",
      "step =  76000 error value =  0.07680442118085883 W =  [[2.25319203]\n",
      " [1.04278875]] , b =  [-26.44973642]\n",
      "step =  76400 error value =  0.07642454905033556 W =  [[2.25613206]\n",
      " [1.04485413]] , b =  [-26.48856506]\n",
      "step =  76800 error value =  0.076048393996888 W =  [[2.25905788]\n",
      " [1.04690904]] , b =  [-26.5272032]\n",
      "step =  77200 error value =  0.07567590196519859 W =  [[2.26196964]\n",
      " [1.04895358]] , b =  [-26.56565268]\n",
      "step =  77600 error value =  0.07530701993948606 W =  [[2.26486746]\n",
      " [1.05098785]] , b =  [-26.60391533]\n",
      "step =  78000 error value =  0.0749416959187422 W =  [[2.26775148]\n",
      " [1.05301196]] , b =  [-26.64199295]\n",
      "step =  78400 error value =  0.07457987889259342 W =  [[2.27062183]\n",
      " [1.05502599]] , b =  [-26.6798873]\n",
      "step =  78800 error value =  0.07422151881788969 W =  [[2.27347863]\n",
      " [1.05703007]] , b =  [-26.71760013]\n",
      "step =  79200 error value =  0.07386656659597063 W =  [[2.27632201]\n",
      " [1.05902427]] , b =  [-26.75513316]\n",
      "step =  79600 error value =  0.073514974050513 W =  [[2.2791521 ]\n",
      " [1.06100869]] , b =  [-26.79248808]\n",
      "step =  80000 error value =  0.07316669390607039 W =  [[2.28196902]\n",
      " [1.06298344]] , b =  [-26.82966656]\n"
     ]
    }
   ],
   "source": [
    "# [5] 학습율 (learning rate) 초기화 및 손실함수가 최소가 될 때까지 W, b 업데이트\n",
    "learning_rate = 1e-2 # 1e-2, 1e-3 은 손실함수 값 발산\n",
    "\n",
    "f = lambda x : loss_func(x_data, t_data)\n",
    "\n",
    "print(\"Initial error value = \", error_val(x_data, t_data), \"Initial W = \", W, \"\\n\", \", b = \", b)\n",
    "\n",
    "for step in range(80001):\n",
    "    \n",
    "    W -= learning_rate * numerical_derivative(f, W)\n",
    "    b -= learning_rate * numerical_derivative(f, b)\n",
    "    \n",
    "    if (step % 400 == 0):\n",
    "        print(\"step = \", step, \"error value = \", error_val(x_data, t_data), \"W = \", W, \", b = \", b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de09db3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [6] 미래 값 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "3c9b99fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.1286396]), 0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([3, 17]) # (예습, 복습) = (3, 17) => Fail(0)\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d68fa74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00099085]), 0)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([5, 8]) # (예습, 복습) = (5, 8) => Fail (0)\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "952fdf21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.99998953]), 1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([7, 21]) # (예습, 복습) = (7, 21) => Pass (1)\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "57d3ffee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.63505424]), 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = np.array([12, 0]) #(예습, 복습) = (12, 0) => Pass (1)\n",
    "predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f175f84",
   "metadata": {},
   "source": [
    "미래 값을 예측해보면, 복습보다는 예습시간이 합격(Pass)에 미치는 영향이 크다는 것을 알 수 있음. (즉, 예습시간에 대한 가중치 W1 = 2.28, 복습시간에 대한 가중치 W2 = 1.06, 에서 보듯이 예습시간이 복습시간에 비해 최종결과에 미치는 영향이 2배 이상임)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
